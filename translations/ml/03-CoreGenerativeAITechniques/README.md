# കോർ ജനറേറ്റീവ് AI ടെക്നിക്‌സ് ട്യൂട്ടോറിയൽ

## ഉള്ളടക്ക പട്ടിക

- [ആവശ്യകതകൾ](../../../03-CoreGenerativeAITechniques)
- [ആരംഭിക്കുക](../../../03-CoreGenerativeAITechniques)
  - [പടി 1: നിങ്ങളുടെ എൻവയോൺമെന്റ് വേരിയബിൾ സജ്ജമാക്കുക](../../../03-CoreGenerativeAITechniques)
  - [പടി 2: ഉദാഹരണങ്ങളുടെ ഡയറക്ടറിയിലേക്ക് പോകുക](../../../03-CoreGenerativeAITechniques)
- [മോഡൽ തിരഞ്ഞെടുക്കൽ മാർഗ്ഗനിർദ്ദേശം](../../../03-CoreGenerativeAITechniques)
- [ട്യൂട്ടോറിയൽ 1: LLM പൂർത്തീകരണങ്ങളും ചാറ്റും](../../../03-CoreGenerativeAITechniques)
- [ട്യൂട്ടോറിയൽ 2: ഫംഗ്ഷൻ കോളിംഗ്](../../../03-CoreGenerativeAITechniques)
- [ട്യൂട്ടോറിയൽ 3: RAG (റിട്രീവൽ-ഓഗ്മെന്റഡ് ജനറേഷൻ)](../../../03-CoreGenerativeAITechniques)
- [ട്യൂട്ടോറിയൽ 4: ഉത്തരവാദിത്വമുള്ള AI](../../../03-CoreGenerativeAITechniques)
- [ഉദാഹരണങ്ങളിൽ പൊതുവായ മാതൃകകൾ](../../../03-CoreGenerativeAITechniques)
- [അടുത്ത ഘട്ടങ്ങൾ](../../../03-CoreGenerativeAITechniques)
- [പ്രശ്നപരിഹാരം](../../../03-CoreGenerativeAITechniques)
  - [പൊതുവായ പ്രശ്നങ്ങൾ](../../../03-CoreGenerativeAITechniques)

## അവലോകനം

ഈ ട്യൂട്ടോറിയൽ ജാവയും GitHub മോഡലുകളും ഉപയോഗിച്ച് പ്രധാന ജനറേറ്റീവ് AI ടെക്നിക്‌സിന്റെ പ്രായോഗിക ഉദാഹരണങ്ങൾ നൽകുന്നു. ലാർജ് ലാംഗ്വേജ് മോഡലുകളുമായി (LLMs) എങ്ങനെ ഇടപെടാം, ഫംഗ്ഷൻ കോളിംഗ് നടപ്പിലാക്കുക, റിട്രീവൽ-ഓഗ്മെന്റഡ് ജനറേഷൻ (RAG) ഉപയോഗിക്കുക, ഉത്തരവാദിത്വമുള്ള AI പ്രാക്ടീസുകൾ പ്രയോഗിക്കുക എന്നിവ നിങ്ങൾ പഠിക്കും.

## ആവശ്യകതകൾ

ആരംഭിക്കുന്നതിന് മുമ്പ്, നിങ്ങൾക്ക് താഴെവരുന്നവ ഉറപ്പാക്കുക:
- Java 21 അല്ലെങ്കിൽ അതിനുമുകളിൽ ഇൻസ്റ്റാൾ ചെയ്തിരിക്കണം
- Maven ഡിപെൻഡൻസി മാനേജ്മെന്റിനായി
- വ്യക്തിഗത ആക്സസ് ടോക്കൺ (PAT) ഉള്ള GitHub അക്കൗണ്ട്

## ആരംഭിക്കുക

### പടി 1: നിങ്ങളുടെ എൻവയോൺമെന്റ് വേരിയബിൾ സജ്ജമാക്കുക

ആദ്യം, GitHub ടോക്കൺ ഒരു എൻവയോൺമെന്റ് വേരിയബിൾ ആയി സജ്ജമാക്കേണ്ടതുണ്ട്. ഈ ടോക്കൺ GitHub മോഡലുകൾ സൗജന്യമായി ആക്സസ് ചെയ്യാൻ അനുവദിക്കുന്നു.

**Windows (കമാൻഡ് പ്രോംപ്റ്റ്):**
```cmd
set GITHUB_TOKEN=your_github_token_here
```

**Windows (PowerShell):**
```powershell
$env:GITHUB_TOKEN="your_github_token_here"
```

**Linux/macOS:**
```bash
export GITHUB_TOKEN=your_github_token_here
```


### പടി 2: ഉദാഹരണങ്ങളുടെ ഡയറക്ടറിയിലേക്ക് പോകുക

```bash
cd 03-CoreGenerativeAITechniques/examples/
```


## മോഡൽ തിരഞ്ഞെടുക്കൽ മാർഗ്ഗനിർദ്ദേശം

ഈ ഉദാഹരണങ്ങൾ അവരുടെ പ്രത്യേക ഉപയോഗ കേസുകൾക്കായി ഓപ്റ്റിമൈസ് ചെയ്ത വിവിധ മോഡലുകൾ ഉപയോഗിക്കുന്നു:

**GPT-4.1-nano** (പൂർത്തീകരണ ഉദാഹരണം):
- അതിവേഗവും ചെലവുകുറഞ്ഞതും
- അടിസ്ഥാന ടെക്സ്റ്റ് പൂർത്തീകരണത്തിനും ചാറ്റിനും അനുയോജ്യം
- അടിസ്ഥാന LLM ഇടപെടൽ മാതൃകകൾ പഠിക്കാൻ അനുയോജ്യം

**GPT-4o-mini** (ഫംഗ്ഷനുകൾ, RAG, ഉത്തരവാദിത്വമുള്ള AI ഉദാഹരണങ്ങൾ):
- ചെറിയതെങ്കിലും പൂർണ്ണമായ "ഓംനി വർക്ക്‌ഹോഴ്സ്" മോഡൽ
- വിവിധ വിൽപ്പനക്കാരിൽ നിന്ന് ഉയർന്ന ശേഷികൾ പിന്തുണയ്ക്കുന്നു:
  - ദൃശ്യ പ്രോസസ്സിംഗ്
  - JSON/സംഘടിത ഔട്ട്പുട്ടുകൾ  
  - ടൂൾ/ഫംഗ്ഷൻ കോളിംഗ്
- നാനോ മോഡലുകളേക്കാൾ കൂടുതൽ ശേഷികൾ, ഉദാഹരണങ്ങൾ സ്ഥിരതയോടെ പ്രവർത്തിക്കുന്നതിൽ ഉറപ്പുനൽകുന്നു

> **ഇത് എന്തുകൊണ്ട് പ്രധാനമാണ്**: "നാനോ" മോഡലുകൾ വേഗത്തിനും ചെലവിനും മികച്ചതാണെങ്കിലും, "മിനി" മോഡലുകൾ ഫംഗ്ഷൻ കോളിംഗ് പോലുള്ള ഉയർന്ന സവിശേഷതകളിലേക്ക് വിശ്വസനീയമായ ആക്സസ് ആവശ്യമുള്ളപ്പോൾ സുരക്ഷിതമായ തിരഞ്ഞെടുപ്പാണ്.

## ട്യൂട്ടോറിയൽ 1: LLM പൂർത്തീകരണങ്ങളും ചാറ്റും

**ഫയൽ:** `src/main/java/com/example/genai/techniques/completions/LLMCompletionsApp.java`

### ഈ ഉദാഹരണം എന്താണ് പഠിപ്പിക്കുന്നത്

ഈ ഉദാഹരണം GitHub മോഡലുകളുമായി ക്ലയന്റ് ഇൻഷിയലൈസേഷൻ, സിസ്റ്റം, ഉപയോക്തൃ പ്രോംപ്റ്റുകൾക്കുള്ള സന്ദേശ ഘടന മാതൃകകൾ, സന്ദേശ ചരിത്ര സമ്പാദനത്തിലൂടെ സംഭാഷണ അവസ്ഥ മാനേജ്മെന്റ്, പ്രതികരണ ദൈർഘ്യവും സൃഷ്ടിപരമായ നിലവാരവും നിയന്ത്രിക്കുന്നതിന് പാരാമീറ്റർ ട്യൂണിംഗ് എന്നിവ ഉൾപ്പെടെ OpenAI API വഴി ലാർജ് ലാംഗ്വേജ് മോഡലുകളുമായി (LLM) ഇടപെടൽ പ്രാഥമിക യാന്ത്രികതകൾ പ്രദർശിപ്പിക്കുന്നു.

### പ്രധാന കോഡ് ആശയങ്ങൾ

#### 1. ക്ലയന്റ് സജ്ജീകരണം
```java
// AI ക്ലയന്റ് സൃഷ്ടിക്കുക
OpenAIClient client = new OpenAIClientBuilder()
    .endpoint("https://models.inference.ai.azure.com")
    .credential(new StaticTokenCredential(pat))
    .buildClient();
```

ഇത് GitHub മോഡലുകളുമായി നിങ്ങളുടെ ടോക്കൺ ഉപയോഗിച്ച് ഒരു കണക്ഷൻ സൃഷ്ടിക്കുന്നു.

#### 2. ലളിതമായ പൂർത്തീകരണം
```java
List<ChatRequestMessage> messages = List.of(
    // സിസ്റ്റം സന്ദേശം AIയുടെ പെരുമാറ്റം സജ്ജമാക്കുന്നു
    new ChatRequestSystemMessage("You are a helpful Java expert."),
    // ഉപയോക്തൃ സന്ദേശം യഥാർത്ഥ ചോദ്യമാണ് ഉൾക്കൊള്ളുന്നത്
    new ChatRequestUserMessage("Explain Java streams briefly.")
);

ChatCompletionsOptions options = new ChatCompletionsOptions(messages)
    .setModel("gpt-4.1-nano")  // അടിസ്ഥാന പൂർത്തീകരണങ്ങൾക്ക് വേഗതയുള്ള, ചെലവുകുറഞ്ഞ മോഡൽ
    .setMaxTokens(200)         // പ്രതികരണ ദൈർഘ്യം പരിമിതപ്പെടുത്തുക
    .setTemperature(0.7);      // സൃഷ്ടിപരത്വം നിയന്ത്രിക്കുക (0.0-1.0)
```

#### 3. സംഭാഷണ മെമ്മറി
```java
// AIയുടെ പ്രതികരണം ചേർത്ത് സംഭാഷണ ചരിത്രം നിലനിർത്തുക
messages.add(new ChatRequestAssistantMessage(aiResponse));
messages.add(new ChatRequestUserMessage("Follow-up question"));
```

AI മുൻ സന്ദേശങ്ങൾ ഓർക്കുന്നത് നിങ്ങൾ അവയെ തുടർന്നുള്ള അഭ്യർത്ഥനകളിൽ ഉൾപ്പെടുത്തുന്നുവെങ്കിൽ മാത്രമാണ്.

### ഉദാഹരണം പ്രവർത്തിപ്പിക്കുക
```bash
mvn compile exec:java -Dexec.mainClass="com.example.genai.techniques.completions.LLMCompletionsApp"
```

### ഇത് പ്രവർത്തിപ്പിക്കുമ്പോൾ എന്താണ് സംഭവിക്കുന്നത്

1. **ലളിതമായ പൂർത്തീകരണം**: AI ഒരു Java ചോദ്യത്തിന് സിസ്റ്റം പ്രോംപ്റ്റ് മാർഗ്ഗനിർദ്ദേശത്തോടെ ഉത്തരം നൽകുന്നു
2. **മൾട്ടി-ടേൺ ചാറ്റ്**: AI നിരവധി ചോദ്യങ്ങളിൽ പ്ര_CONTEXT_

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**അസത്യവാദം**:  
ഈ രേഖ AI വിവർത്തന സേവനമായ [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ച് വിവർത്തനം ചെയ്തതാണ്. കൃത്യതയ്ക്കായി ഞങ്ങൾ ശ്രമിക്കുന്നുവെങ്കിലും, ഓട്ടോമേറ്റഡ് വിവർത്തനങ്ങളിൽ പിശകുകൾ അല്ലെങ്കിൽ തെറ്റായ വിവരങ്ങൾ ഉണ്ടാകാൻ സാധ്യതയുണ്ട്. അതിന്റെ സ്വാഭാവിക ഭാഷയിലുള്ള മൗലിക രേഖ പ്രാമാണികമായ ഉറവിടമായി പരിഗണിക്കണം. നിർണായകമായ വിവരങ്ങൾക്ക്, പ്രൊഫഷണൽ മനുഷ്യ വിവർത്തനം ശുപാർശ ചെയ്യുന്നു. ഈ വിവർത്തനം ഉപയോഗിച്ച് ഉണ്ടാകുന്ന തെറ്റിദ്ധാരണകൾക്കോ തെറ്റായ വ്യാഖ്യാനങ്ങൾക്കോ ഞങ്ങൾ ഉത്തരവാദികളല്ല.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->